"""
æœåŠ¡å™¨ä¸»æ¨¡å—
å®ç°äº†åŸºäºFastAPIçš„WebæœåŠ¡å™¨ï¼Œæ”¯æŒWebSocketå’ŒWebRTCé€šè®¯
"""

from queue import Queue, Empty
import logging
from logsetup import setup_logging
setup_logging(logging.INFO)
logger = logging.getLogger(__name__)

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from starlette.responses import HTMLResponse, Response, FileResponse
from contextlib import asynccontextmanager
import uvicorn
import asyncio
import json

from communication.config import (
    CommunicationConfig,
    ProtocolType,
    WebSocketConfig,
    WebRTCConfig
)
from communication.websocket_protocol import WebSocketProtocol
from communication.webrtc_protocol import WebRTCProtocol
from speech_pipeline_manager import SpeechPipelineManager
from audio_in import AudioInputProcessor
from upsample_overlap import UpsampleOverlap

# é…ç½®å‚æ•°
USE_SSL = False
TTS_START_ENGINE = "coqui"
LLM_START_PROVIDER = "ollama"
LLM_START_MODEL = "hf.co/bartowski/huihui-ai_Mistral-Small-24B-Instruct-2501-abliterated-GGUF:Q4_K_M"
NO_THINK = False
DIRECT_STREAM = False

# é€šè®¯é…ç½®
COMM_CONFIG = CommunicationConfig(
    protocol_type=ProtocolType.WEBSOCKET,  # é»˜è®¤ä½¿ç”¨WebSocket
    websocket_config=WebSocketConfig(
        host="0.0.0.0",
        port=8000,
        path="/ws"
    ),
    webrtc_config=WebRTCConfig(
        stun_servers=["stun:stun.l.google.com:19302"]
    )
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ç®¡ç†åº”ç”¨ç¨‹åºçš„ç”Ÿå‘½å‘¨æœŸ
    åˆå§‹åŒ–å…¨å±€ç»„ä»¶å¹¶åœ¨å…³é—­æ—¶æ¸…ç†èµ„æº
    """
    logger.info("ğŸ–¥ï¸â–¶ï¸ æœåŠ¡å™¨å¯åŠ¨ä¸­")
    
    # åˆå§‹åŒ–å…¨å±€ç»„ä»¶
    app.state.SpeechPipelineManager = SpeechPipelineManager(
        tts_engine=TTS_START_ENGINE,
        llm_provider=LLM_START_PROVIDER,
        llm_model=LLM_START_MODEL,
        no_think=NO_THINK
    )
    
    app.state.Upsampler = UpsampleOverlap()
    app.state.AudioInputProcessor = AudioInputProcessor(
        "en",
        is_orpheus=TTS_START_ENGINE=="orpheus",
        pipeline_latency=app.state.SpeechPipelineManager.full_output_pipeline_latency / 1000
    )
    
    yield
    
    logger.info("ğŸ–¥ï¸â¹ï¸ æœåŠ¡å™¨å…³é—­ä¸­")
    app.state.AudioInputProcessor.shutdown()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(lifespan=lifespan)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æŒ‚è½½é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/")
async def get_index() -> HTMLResponse:
    """è¿”å›ä¸»é¡µ"""
    with open("static/index.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    return HTMLResponse(content=html_content)

@app.get("/favicon.ico")
async def favicon():
    """è¿”å›ç½‘ç«™å›¾æ ‡"""
    return FileResponse("static/favicon.ico")

# WebSocketè·¯ç”±
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocketè¿æ¥å¤„ç†"""
    protocol = WebSocketProtocol(COMM_CONFIG.websocket_config)
    protocol.websocket = websocket
    
    try:
        await protocol.initialize()
        await protocol.connect()
        
        # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks = {
            "on_partial": lambda txt: asyncio.create_task(protocol.send_text(json.dumps({"type": "partial", "text": txt}))),
            "on_final": lambda txt: asyncio.create_task(protocol.send_text(json.dumps({"type": "final", "text": txt}))),
            "on_audio": lambda audio: asyncio.create_task(protocol.send_audio(audio))
        }
        await protocol.set_callbacks(callbacks)
        
        # å¤„ç†éŸ³é¢‘æ•°æ®
        async for audio_data in protocol.receive_audio():
            await app.state.AudioInputProcessor.process_audio(audio_data)
            
    except WebSocketDisconnect:
        logger.info("WebSocketè¿æ¥æ–­å¼€")
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {str(e)}")
    finally:
        await protocol.disconnect()

# WebRTCè·¯ç”±
@app.post("/webrtc/offer")
async def webrtc_offer(offer: dict):
    """å¤„ç†WebRTC offerè¯·æ±‚"""
    try:
        protocol = WebRTCProtocol(COMM_CONFIG.webrtc_config)
        await protocol.initialize()
        
        # è®¾ç½®å›è°ƒå‡½æ•°
        callbacks = {
            "on_partial": lambda txt: asyncio.create_task(protocol.send_text(json.dumps({"type": "partial", "text": txt}))),
            "on_final": lambda txt: asyncio.create_task(protocol.send_text(json.dumps({"type": "final", "text": txt}))),
            "on_audio": lambda audio: asyncio.create_task(protocol.send_audio(audio))
        }
        await protocol.set_callbacks(callbacks)
        
        # å¤„ç†offer
        answer = await protocol.create_offer()
        return {"sdp": answer.sdp, "type": answer.type}
    except Exception as e:
        logger.error(f"WebRTC offerå¤„ç†é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/webrtc/answer")
async def webrtc_answer(answer: dict):
    """å¤„ç†WebRTC answerè¯·æ±‚"""
    try:
        protocol = WebRTCProtocol(COMM_CONFIG.webrtc_config)
        await protocol.handle_answer(answer)
        
        # å¤„ç†éŸ³é¢‘æ•°æ®
        async for audio_data in protocol.receive_audio():
            await app.state.AudioInputProcessor.process_audio(audio_data)
            
        return {"status": "success"}
    except Exception as e:
        logger.error(f"WebRTC answerå¤„ç†é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(
        "server:app",
        host=COMM_CONFIG.websocket_config.host,
        port=COMM_CONFIG.websocket_config.port,
        ssl_keyfile="key.pem" if USE_SSL else None,
        ssl_certfile="cert.pem" if USE_SSL else None
    )
